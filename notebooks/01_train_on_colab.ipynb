{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADAS Object Detection - Training on Google Colab\n",
    "\n",
    "This notebook trains YOLOv8 on BDD100K dataset using Google Colab's free GPU.\n",
    "\n",
    "**Runtime**: Select GPU runtime (Runtime > Change runtime type > GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/Pranav1011/ADAS-OBJECT-DETECTION.git\n",
    "%cd ADAS-OBJECT-DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q ultralytics opencv-python albumentations wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download BDD100K Dataset\n",
    "\n",
    "**Option A**: Upload from Google Drive (recommended)\n",
    "1. Download BDD100K from https://bdd-data.berkeley.edu/\n",
    "2. Upload to your Google Drive\n",
    "3. Mount and copy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy dataset from Drive (adjust paths as needed)\n",
    "!mkdir -p data/raw\n",
    "!cp /content/drive/MyDrive/datasets/bdd100k_images_10k.zip data/raw/\n",
    "!cp /content/drive/MyDrive/datasets/bdd100k_labels_release.zip data/raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dataset\n",
    "!cd data/raw && unzip -q bdd100k_images_10k.zip\n",
    "!cd data/raw && unzip -q bdd100k_labels_release.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert Annotations to YOLO Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert BDD100K to YOLO format\n",
    "!python -m data_pipeline.convert_annotations \\\n",
    "    --bdd-root data/raw \\\n",
    "    --output-dir data/processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset\n",
    "!ls -la data/processed/\n",
    "!cat data/processed/dataset.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train YOLOv8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv8m model\n",
    "model = YOLO('yolov8m.pt')\n",
    "\n",
    "# Train\n",
    "results = model.train(\n",
    "    data='data/processed/dataset.yaml',\n",
    "    epochs=100,\n",
    "    batch=16,  # Adjust based on GPU memory (8 for T4, 16 for A100)\n",
    "    imgsz=640,\n",
    "    patience=20,\n",
    "    device=0,\n",
    "    project='runs/train',\n",
    "    name='yolov8m-bdd100k',\n",
    "    exist_ok=True,\n",
    "    pretrained=True,\n",
    "    optimizer='AdamW',\n",
    "    lr0=0.001,\n",
    "    cos_lr=True,\n",
    "    warmup_epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "metrics = model.val(data='data/processed/dataset.yaml')\n",
    "print(f\"mAP@0.5: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP@0.5:0.95: {metrics.box.map:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to ONNX\n",
    "model.export(format='onnx', imgsz=640, simplify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy best weights to weights folder\n",
    "!mkdir -p weights\n",
    "!cp runs/train/yolov8m-bdd100k/weights/best.pt weights/\n",
    "!cp runs/train/yolov8m-bdd100k/weights/best.onnx weights/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained weights to Google Drive\n",
    "!cp -r weights /content/drive/MyDrive/adas-detection/\n",
    "!cp -r runs/train/yolov8m-bdd100k /content/drive/MyDrive/adas-detection/\n",
    "print(\"Saved to Google Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Quantization (Optional)\n",
    "\n",
    "Run INT8 quantization for faster inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ONNX Runtime\n",
    "!pip install -q onnxruntime\n",
    "\n",
    "# Run quantization\n",
    "!python -m quantization.onnx_quantize \\\n",
    "    --model weights/best.onnx \\\n",
    "    --calibration-dir data/processed/images/val \\\n",
    "    --num-calibration 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. TensorRT Optimization (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to TensorRT (requires NVIDIA GPU)\n",
    "model.export(\n",
    "    format='engine',\n",
    "    imgsz=640,\n",
    "    half=True,  # FP16\n",
    "    device=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Benchmark Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark all models\n",
    "!python -m quantization.benchmark \\\n",
    "    --models-dir weights \\\n",
    "    --runs 100"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
